{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('../project_data/specialist_text.txt') as f:\n",
    "    data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncleaned words =  9035\n",
      "Removed Stop Words =  5091\n",
      "Removed numbers and punctuation =  3819\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(data)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print (\"Uncleaned words = \", len(tokens))\n",
    "\n",
    "## Remove Stop Words\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "new_stop = ['and','experience','show','veteran','less','origin','sexual', 'orientation', 'dental', 'insurance', 'hour', 'shift','religion','sex','receive','consideration','pay', 'per','employment','opportunity','consideration', 'employment','job','description','start', 'job','click','gender','benefits', 'k','monday', 'friday','age', 'disability','please', 'visit','salary', 'range','characteristic', 'protected','minimum', 'qualifications','join','reasonable', 'accommodation', 'parental', 'leave', 'medical', 'vision', 'duties', 'responsibilities','business', 'needs','essential', 'functions','color','type', 'fulltime','verbal', 'communication','apply','work','national', 'status','closely','flexible', 'spending','’','ability', 'work','location', 'remote','capital', 'one','marital', 'status','team', 'members','work', 'location','applicants', 'without','paid', 'time','color','regard', 'race','apply','equal', 'employer','without', 'regard','united', 'states',\"'s\",'race', 'color','best', 'practices','physical', 'mental','health', 'savings','responsible','affirmative', 'action','iam','federal','state','local','required','ideal', 'candidate','individuals', 'disabilities','northrop', 'grumman','applicable', 'law','every', 'day','across', 'organization''travel', 'required','track', 'record''including', 'limited','employee', 'assistance','new', 'york','compensation', 'package','financial', 'services','travel', 'requirements','create', 'maintain','pre', 'posttax', 'options','discriminate','diversity', 'equity', 'inclusion','matrix', 'committed', 'providing','qualified', 'applicant','vista', 'portfolio', 'company','related', 'field', 'equivalent','bae','nike' ,'inc','familiar','children', 'hospital', 'philadelphia','weill', 'cornell', 'medicine', 'salt', 'city','eagle','title', 'vaccinated', 'covid19','ix','education','mantech','western','401','match','529','american,','express','colleague','baker','qualify', 'religious', 'exemption','regard', 'criminal', 'background','inquiry','us', 'puerto', 'rico','must', 'able', 'deliver','temperature', 'excursion','obtain', 'public','trust','arrest', 'conviction', 'record','including', 'pregnancy', 'childbirth','general', 'holdings', 'corp','genetic', 'registered', 'domestic']\n",
    "\n",
    "technical_stop = ['identity','engineer','management','information','manager','security','user','administrator','hardware', 'software','analyst','architect','systems','engineering']\n",
    "\n",
    "stop.extend(new_stop + technical_stop)\n",
    "\n",
    "words=[]\n",
    "for w in tokens:\n",
    "    words.append(wordnet_lemmatizer.lemmatize(w))  \n",
    "\n",
    "tokens_list=[]\n",
    "for word in words:\n",
    "    tokens_list.append(word.lower())\n",
    "\n",
    "token_list1 = [ ]\n",
    "for word in tokens_list:\n",
    "    if word not in stop:\n",
    "        token_list1.append(word)\n",
    "\n",
    "print(\"Removed Stop Words = \",len(token_list1))\n",
    "\n",
    "## Remove numbers and punctuation\n",
    "punctuation = re.compile(r'[-.?!,\":;()&@#%^*·`$[]')\n",
    "token_list2 = [ ]\n",
    "for token in token_list1:\n",
    "    word = punctuation.sub(\"\", token)\n",
    "    if len(word)>0:\n",
    "        token_list2.append(word)\n",
    "print(\"Removed numbers and punctuation = \",len(token_list2))\n",
    "\n",
    "#print(token_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering non-nouns and Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NN</td>\n",
       "      <td>2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JJ</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VBG</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NNS</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VBP</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RB</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VBD</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VB</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VBN</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IN</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MD</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JJR</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JJS</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NNP</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRP</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RBR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FW</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WP$</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TO</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>POS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    POS  word\n",
       "9    NN  2066\n",
       "5    JJ   655\n",
       "19  VBG   257\n",
       "11  NNS   128\n",
       "1    CD   116\n",
       "21  VBP   111\n",
       "14   RB    91\n",
       "18  VBD    88\n",
       "17   VB    76\n",
       "20  VBN    57\n",
       "4    IN    56\n",
       "22  VBZ    53\n",
       "8    MD    15\n",
       "6   JJR     8\n",
       "7   JJS     8\n",
       "10  NNP     7\n",
       "13  PRP     6\n",
       "15  RBR     5\n",
       "3    FW     5\n",
       "0    CC     5\n",
       "23  WP$     2\n",
       "16   TO     2\n",
       "2    DT     1\n",
       "12  POS     1"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens_pos_tag = nltk.pos_tag(token_list2)\n",
    "pos_df = pd.DataFrame(tokens_pos_tag, columns = ('word','POS'))\n",
    "\n",
    "pos_sum = pos_df.groupby('POS', as_index=False).count() # group by POS tags\n",
    "pos_sum.sort_values(['word'], ascending=[False]) # in descending order of number of words per tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered words =  2201\n",
      "[(('system', 'NN'), 47), (('access', 'NN'), 46), (('support', 'NN'), 40), (('year', 'NN'), 33), (('process', 'NN'), 28), (('service', 'NN'), 27), (('application', 'NN'), 25), (('problem', 'NN'), 25), (('knowledge', 'NN'), 23), (('position', 'NN'), 23), (('program', 'NN'), 22), (('customer', 'NN'), 21), (('specialist', 'NN'), 20), (('technology', 'NN'), 20), (('material', 'NN'), 19), (('role', 'NN'), 17), (('data', 'NNS'), 16), (('issue', 'NN'), 16), (('project', 'NN'), 15), (('database', 'NN'), 14), (('skill', 'NN'), 14), (('requirement', 'NN'), 13), (('development', 'NN'), 13), (('quality', 'NN'), 13), (('solution', 'NN'), 12), (('master', 'NN'), 12), (('environment', 'NN'), 12), (('benefit', 'NN'), 11), (('certification', 'NN'), 11), (('maintenance', 'NN'), 11), (('plan', 'NN'), 11), (('request', 'NN'), 11), (('control', 'NN'), 10), (('manage', 'NN'), 10), (('network', 'NN'), 10), (('level', 'NN'), 10), (('policy', 'NN'), 10), (('implementation', 'NN'), 10), (('contract', 'NN'), 9), (('duty', 'NN'), 9), (('activity', 'NN'), 9), (('product', 'NN'), 8), (('task', 'NN'), 8), (('government', 'NN'), 8), (('assurance', 'NN'), 8), (('resolution', 'NN'), 8), (('payroll', 'NN'), 8), (('compliance', 'NN'), 8), (('degree', 'NN'), 7), (('industry', 'NN'), 7), (('performance', 'NN'), 7), (('clearance', 'NN'), 7), (('life', 'NN'), 7), (('offering', 'NN'), 7), (('creation', 'NN'), 7), (('career', 'NN'), 7), (('help', 'NN'), 7), (('peraton', 'NN'), 7), (('organization', 'NN'), 6), (('tool', 'NN'), 6), (('bachelor', 'NN'), 6), (('basis', 'NN'), 6), (('client', 'NN'), 6), (('computer', 'NN'), 6), (('production', 'NN'), 6), (('oracle', 'NN'), 6), (('question', 'NN'), 6), (('expert', 'NN'), 6), (('stability', 'NN'), 6), (('department', 'NN'), 6), (('office', 'NN'), 6), (('review', 'NN'), 6), (('administration', 'NN'), 6), (('use', 'NN'), 6), (('account', 'NN'), 5), (('risk', 'NN'), 5), (('stakeholder', 'NN'), 5), (('hexagon', 'NN'), 5), (('partner', 'NN'), 5), (('printer', 'NN'), 5), (('equipment', 'NN'), 5), (('assist', 'NN'), 5), (('query', 'NN'), 5), (('sailpoint', 'NN'), 5), (('azure', 'NN'), 5), (('code', 'NN'), 5), (('logistics', 'NNS'), 5), (('functionality', 'NN'), 5), (('setup', 'NN'), 5), (('source', 'NN'), 5), (('count', 'NN'), 5), (('manner', 'NN'), 5), (('progress', 'NN'), 5), (('order', 'NN'), 5), (('expression', 'NN'), 5), (('documentation', 'NN'), 5), (('personnel', 'NNS'), 5), (('base', 'NN'), 5), (('agency', 'NN'), 5), (('term', 'NN'), 5)]\n"
     ]
    }
   ],
   "source": [
    "filtered_pos = [ ]\n",
    "for one in tokens_pos_tag:\n",
    "    if one[1] == 'NN' or one[1] == 'NNS' or one[1] == 'NNP' or one[1] == 'NNPS':\n",
    "        filtered_pos.append(one)\n",
    "print (\"Filtered words = \",len(filtered_pos))\n",
    "\n",
    "fdist_pos = nltk.FreqDist(filtered_pos)\n",
    "top_100_words = fdist_pos.most_common(100)\n",
    "print(top_100_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(system, NN)</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(access, NN)</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(support, NN)</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(year, NN)</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(process, NN)</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pos  count\n",
       "0   (system, NN)     47\n",
       "1   (access, NN)     46\n",
       "2  (support, NN)     40\n",
       "3     (year, NN)     33\n",
       "4  (process, NN)     28"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df = pd.DataFrame(top_100_words, columns = ('pos','count'))\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_39764/2050492311.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  top_words_df = top_words_df.drop('pos', 1) # drop the previous column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>process</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count     Word\n",
       "0     47   system\n",
       "1     46   access\n",
       "2     40  support\n",
       "3     33     year\n",
       "4     28  process"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df['Word'] = top_words_df['pos'].apply(lambda x: x[0]) # split the tuple of POS\n",
    "top_words_df = top_words_df.drop('pos', 1) # drop the previous column\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('system', 47), ('access', 46), ('support', 40), ('year', 33), ('process', 28), ('service', 27), ('application', 25), ('problem', 25), ('knowledge', 23), ('position', 23), ('program', 22), ('customer', 21), ('specialist', 20), ('technology', 20), ('material', 19), ('role', 17), ('data', 16), ('issue', 16), ('project', 15), ('database', 14), ('skill', 14), ('requirement', 13), ('development', 13), ('quality', 13), ('solution', 12), ('master', 12), ('environment', 12), ('benefit', 11), ('certification', 11), ('maintenance', 11), ('plan', 11), ('request', 11), ('control', 10), ('manage', 10), ('network', 10), ('level', 10), ('policy', 10), ('implementation', 10), ('contract', 9), ('duty', 9), ('activity', 9), ('product', 8), ('task', 8), ('government', 8), ('assurance', 8), ('resolution', 8), ('payroll', 8), ('compliance', 8), ('degree', 7), ('industry', 7), ('performance', 7), ('clearance', 7), ('life', 7), ('offering', 7), ('creation', 7), ('career', 7), ('help', 7), ('peraton', 7), ('organization', 6), ('tool', 6), ('bachelor', 6), ('basis', 6), ('client', 6), ('computer', 6), ('production', 6), ('oracle', 6), ('question', 6), ('expert', 6), ('stability', 6), ('department', 6), ('office', 6), ('review', 6), ('administration', 6), ('use', 6), ('account', 5), ('risk', 5), ('stakeholder', 5), ('hexagon', 5), ('partner', 5), ('printer', 5), ('equipment', 5), ('assist', 5), ('query', 5), ('sailpoint', 5), ('azure', 5), ('code', 5), ('logistics', 5), ('functionality', 5), ('setup', 5), ('source', 5), ('count', 5), ('manner', 5), ('progress', 5), ('order', 5), ('expression', 5), ('documentation', 5), ('personnel', 5), ('base', 5), ('agency', 5), ('term', 5)]\n"
     ]
    }
   ],
   "source": [
    "subset_pos = top_words_df[['Word', 'count']]\n",
    "tuples_pos = [tuple(x) for x in subset_pos.values]\n",
    "\n",
    "print(tuples_pos)\n",
    "\n",
    "wordcloud = WordCloud()\n",
    "#wordcloud.generate_from_frequencies(tuples_pos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "#plt.imshow(wordcloud, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BiGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(material, master)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(quality, assurance)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(3, year)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(year, preferred)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(bachelor, degree)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(high, school)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(production, contingency)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      bigram  count\n",
       "0         (material, master)     10\n",
       "1       (quality, assurance)      8\n",
       "2                  (3, year)      7\n",
       "3          (year, preferred)      6\n",
       "4         (bachelor, degree)      4\n",
       "5             (high, school)      4\n",
       "6  (production, contingency)      4"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgs = nltk.bigrams(token_list2)\n",
    "fdist2 = nltk.FreqDist(bgs) # selecting bigrams from tokens\n",
    "bgs_100 = fdist2.most_common(100) # top-100 bigrams\n",
    "bgs_df = pd.DataFrame(bgs_100, columns = ('bigram','count'))\n",
    "bgs_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(production, contingency, plan)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(excellent, oral, written)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(provide, technical, support)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(testing, collaborating, global)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(collaborating, global, ey)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(disaster, recovery, disaster)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(recovery, disaster, recovery)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            trigram  count\n",
       "0   (production, contingency, plan)      3\n",
       "1        (excellent, oral, written)      2\n",
       "2     (provide, technical, support)      2\n",
       "3  (testing, collaborating, global)      2\n",
       "4       (collaborating, global, ey)      2\n",
       "5    (disaster, recovery, disaster)      2\n",
       "6    (recovery, disaster, recovery)      2"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs = nltk.trigrams(token_list2) \n",
    "fdist3 = nltk.FreqDist(tgs) # selecting trigrams from tokens\n",
    "tgs_100 = fdist3.most_common(100) # top-100 trigrams\n",
    "tgs_df = pd.DataFrame(tgs_100, columns = ('trigram','count'))\n",
    "tgs_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "      <th>phrase</th>\n",
       "      <th>filter_tgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(production, contingency, plan)</td>\n",
       "      <td>3</td>\n",
       "      <td>production contingency plan</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(excellent, oral, written)</td>\n",
       "      <td>2</td>\n",
       "      <td>excellent oral written</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(provide, technical, support)</td>\n",
       "      <td>2</td>\n",
       "      <td>provide technical support</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(testing, collaborating, global)</td>\n",
       "      <td>2</td>\n",
       "      <td>testing collaborating global</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(collaborating, global, ey)</td>\n",
       "      <td>2</td>\n",
       "      <td>collaborating global ey</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            trigram  count                        phrase  \\\n",
       "0   (production, contingency, plan)      3   production contingency plan   \n",
       "1        (excellent, oral, written)      2        excellent oral written   \n",
       "2     (provide, technical, support)      2     provide technical support   \n",
       "3  (testing, collaborating, global)      2  testing collaborating global   \n",
       "4       (collaborating, global, ey)      2       collaborating global ey   \n",
       "\n",
       "   filter_tgs  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_df['phrase'] = tgs_df['trigram'].apply(lambda x: x[0]+\" \"+x[1]+\" \"+x[2]) # merging the tuple into a string\n",
    "tgs_df['filter_tgs'] = tgs_df['phrase'].str.contains(punctuation) # finding strings with numbers and punctuation\n",
    "tgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_39764/1650553726.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tgs_df = tgs_df.drop('trigram', 1)\n",
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_39764/1650553726.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tgs_df = tgs_df.drop('filter_tgs', 1) # removing the excess columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>production contingency plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>excellent oral written</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>provide technical support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>testing collaborating global</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>collaborating global ey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>disaster recovery disaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>recovery disaster recovery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>implementing project following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>project following azure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>following azure aws</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                          phrase\n",
       "0      3     production contingency plan\n",
       "1      2          excellent oral written\n",
       "2      2       provide technical support\n",
       "3      2    testing collaborating global\n",
       "4      2         collaborating global ey\n",
       "5      2      disaster recovery disaster\n",
       "6      2      recovery disaster recovery\n",
       "7      2  implementing project following\n",
       "8      2         project following azure\n",
       "9      2             following azure aws"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_df = tgs_df[tgs_df.filter_tgs == False] # removing strings with numbers and punctuation\n",
    "tgs_df = tgs_df.drop('trigram', 1)\n",
    "tgs_df = tgs_df.drop('filter_tgs', 1) # removing the excess columns\n",
    "tgs_df.reset_index()\n",
    "tgs_df.head(10) #Final trigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
