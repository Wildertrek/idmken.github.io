{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import ngrams\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "with open('../project_data/administrator_text.txt') as f:\n",
    "    data = f.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncleaned words =  12441\n",
      "Removed Stop Words =  7193\n",
      "Removed numbers and punctuation =  5459\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(data)\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print (\"Uncleaned words = \", len(tokens))\n",
    "\n",
    "## Remove Stop Words\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "new_stop = ['and','experience','show','veteran','less','origin','sexual', 'orientation', 'dental', 'insurance', 'hour', 'shift','religion','sex','receive','consideration','pay', 'per','employment','opportunity','consideration', 'employment','job','description','start', 'job','click','gender','benefits', 'k','monday', 'friday','age', 'disability','please', 'visit','salary', 'range','characteristic', 'protected','minimum', 'qualifications','join','reasonable', 'accommodation', 'parental', 'leave', 'medical', 'vision', 'duties', 'responsibilities','business', 'needs','essential', 'functions','color','type', 'fulltime','verbal', 'communication','apply','work','national', 'status','closely','flexible', 'spending','’','ability', 'work','location', 'remote','capital', 'one','marital', 'status','team', 'members','work', 'location','applicants', 'without','paid', 'time','color','regard', 'race','apply','equal', 'employer','without', 'regard','united', 'states',\"'s\",'race', 'color','best', 'practices','physical', 'mental','health', 'savings','responsible','affirmative', 'action','iam','federal','state','local','required','ideal', 'candidate','individuals', 'disabilities','northrop', 'grumman','applicable', 'law','every', 'day','across', 'organization''travel', 'required','track', 'record''including', 'limited','employee', 'assistance','new', 'york','compensation', 'package','financial', 'services','travel', 'requirements','create', 'maintain','pre', 'posttax', 'options','discriminate','diversity', 'equity', 'inclusion','matrix', 'committed', 'providing','qualified', 'applicant','vista', 'portfolio', 'company','related', 'field', 'equivalent','bae','nike' ,'inc','familiar','children', 'hospital', 'philadelphia','weill', 'cornell', 'medicine', 'salt', 'city','eagle','title', 'vaccinated', 'covid19','ix','education','mantech','western','401','match','529','american,','express','colleague','baker','qualify', 'religious', 'exemption','regard', 'criminal', 'background','inquiry','us', 'puerto', 'rico','must', 'able', 'deliver','temperature', 'excursion','obtain', 'public','trust','arrest', 'conviction', 'record','including', 'pregnancy', 'childbirth','general', 'holdings', 'corp','genetic', 'registered', 'domestic']\n",
    "\n",
    "technical_stop = ['identity','engineer','management','information','manager','security','user','administrator','hardware', 'software','analyst','architect','systems','engineering']\n",
    "\n",
    "stop.extend(new_stop + technical_stop)\n",
    "\n",
    "words=[]\n",
    "for w in tokens:\n",
    "    words.append(wordnet_lemmatizer.lemmatize(w))  \n",
    "\n",
    "tokens_list=[]\n",
    "for word in words:\n",
    "    tokens_list.append(word.lower())\n",
    "\n",
    "token_list1 = [ ]\n",
    "for word in tokens_list:\n",
    "    if word not in stop:\n",
    "        token_list1.append(word)\n",
    "\n",
    "print(\"Removed Stop Words = \",len(token_list1))\n",
    "\n",
    "## Remove numbers and punctuation\n",
    "punctuation = re.compile(r'[-.?!,\":;()&@#%^*·`$[]')\n",
    "token_list2 = [ ]\n",
    "for token in token_list1:\n",
    "    word = punctuation.sub(\"\", token)\n",
    "    if len(word)>0:\n",
    "        token_list2.append(word)\n",
    "print(\"Removed numbers and punctuation = \",len(token_list2))\n",
    "\n",
    "#print(token_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filtering non-nouns and Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NN</td>\n",
       "      <td>2904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JJ</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VBG</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NNS</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>VBP</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RB</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>VBD</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>VB</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>VBZ</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>VBN</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>IN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MD</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NNP</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>JJR</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>''</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JJS</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FW</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RBR</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>WP</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRP</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WDT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>WRB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    POS  word\n",
       "11   NN  2904\n",
       "7    JJ   964\n",
       "19  VBG   320\n",
       "13  NNS   194\n",
       "21  VBP   183\n",
       "15   RB   154\n",
       "3    CD   149\n",
       "18  VBD   126\n",
       "17   VB   111\n",
       "22  VBZ    85\n",
       "20  VBN    84\n",
       "6    IN    71\n",
       "10   MD    28\n",
       "12  NNP    21\n",
       "8   JJR    12\n",
       "1    ''    11\n",
       "9   JJS    10\n",
       "5    FW     9\n",
       "2    CC     6\n",
       "16  RBR     5\n",
       "24   WP     4\n",
       "14  PRP     3\n",
       "4    DT     2\n",
       "0     $     1\n",
       "23  WDT     1\n",
       "25  WRB     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokens_pos_tag = nltk.pos_tag(token_list2)\n",
    "pos_df = pd.DataFrame(tokens_pos_tag, columns = ('word','POS'))\n",
    "\n",
    "pos_sum = pos_df.groupby('POS', as_index=False).count() # group by POS tags\n",
    "pos_sum.sort_values(['word'], ascending=[False]) # in descending order of number of words per tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered words =  3119\n",
      "[(('access', 'NN'), 80), (('system', 'NN'), 79), (('application', 'NN'), 46), (('support', 'NN'), 38), (('service', 'NN'), 36), (('environment', 'NN'), 34), (('technology', 'NN'), 32), (('oracle', 'NN'), 32), (('year', 'NN'), 29), (('solution', 'NN'), 28), (('knowledge', 'NN'), 28), (('data', 'NNS'), 27), (('database', 'NN'), 26), (('computer', 'NN'), 25), (('directory', 'NN'), 23), (('position', 'NN'), 22), (('issue', 'NN'), 21), (('development', 'NN'), 21), (('administration', 'NN'), 20), (('design', 'NN'), 19), (('role', 'NN'), 18), (('process', 'NN'), 18), (('organization', 'NN'), 18), (('performance', 'NN'), 18), (('office', 'NN'), 17), (('documentation', 'NN'), 17), (('staff', 'NN'), 17), (('skill', 'NN'), 17), (('customer', 'NN'), 16), (('benefit', 'NN'), 15), (('problem', 'NN'), 15), (('account', 'NN'), 15), (('platform', 'NN'), 14), (('value', 'NN'), 14), (('policy', 'NN'), 14), (('implementation', 'NN'), 13), (('request', 'NN'), 13), (('program', 'NN'), 13), (('community', 'NN'), 13), (('server', 'NN'), 13), (('university', 'NN'), 12), (('azure', 'NN'), 12), (('product', 'NN'), 11), (('task', 'NN'), 11), (('project', 'NN'), 11), (('culture', 'NN'), 11), (('berkeley', 'NN'), 11), (('practice', 'NN'), 11), (('area', 'NN'), 10), (('department', 'NN'), 10), (('integration', 'NN'), 10), (('procedure', 'NN'), 10), (('client', 'NN'), 10), (('people', 'NNS'), 10), (('configuration', 'NN'), 10), (('integrity', 'NN'), 10), (('infrastructure', 'NN'), 10), (('life', 'NN'), 10), (('device', 'NN'), 10), (('enterprise', 'NN'), 10), (('standard', 'NN'), 9), (('member', 'NN'), 9), (('career', 'NN'), 9), (('requirement', 'NN'), 9), (('perform', 'NN'), 9), (('report', 'NN'), 9), (('audit', 'NN'), 9), (('level', 'NN'), 9), (('certification', 'NN'), 9), (('principle', 'NN'), 9), (('assist', 'NN'), 9), (('plan', 'NN'), 9), (('and/or', 'NN'), 8), (('use', 'NN'), 8), (('resource', 'NN'), 8), (('group', 'NN'), 8), (('activity', 'NN'), 8), (('resolution', 'NN'), 8), (('manage', 'NN'), 8), (('degree', 'NN'), 8), (('cloud', 'NN'), 8), (('analysis', 'NN'), 8), (('tool', 'NN'), 8), (('growth', 'NN'), 7), (('partner', 'NN'), 7), (('improvement', 'NN'), 7), (('network', 'NN'), 7), (('ha', 'NN'), 7), (('relationship', 'NN'), 7), (('–', 'NNP'), 7), (('effort', 'NN'), 7), (('hire', 'NN'), 7), (('vendor', 'NN'), 7), (('order', 'NN'), 7), (('backup', 'NN'), 7), (('contract', 'NN'), 7), (('siteminder', 'NN'), 7), (('part', 'NN'), 6), (('compliance', 'NN'), 6), (('condition', 'NN'), 6)]\n"
     ]
    }
   ],
   "source": [
    "filtered_pos = [ ]\n",
    "for one in tokens_pos_tag:\n",
    "    if one[1] == 'NN' or one[1] == 'NNS' or one[1] == 'NNP' or one[1] == 'NNPS':\n",
    "        filtered_pos.append(one)\n",
    "print (\"Filtered words = \",len(filtered_pos))\n",
    "\n",
    "fdist_pos = nltk.FreqDist(filtered_pos)\n",
    "top_100_words = fdist_pos.most_common(100)\n",
    "print(top_100_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(access, NN)</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(system, NN)</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(application, NN)</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(support, NN)</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(service, NN)</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 pos  count\n",
       "0       (access, NN)     80\n",
       "1       (system, NN)     79\n",
       "2  (application, NN)     46\n",
       "3      (support, NN)     38\n",
       "4      (service, NN)     36"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df = pd.DataFrame(top_100_words, columns = ('pos','count'))\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_57644/2050492311.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  top_words_df = top_words_df.drop('pos', 1) # drop the previous column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79</td>\n",
       "      <td>system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>support</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count         Word\n",
       "0     80       access\n",
       "1     79       system\n",
       "2     46  application\n",
       "3     38      support\n",
       "4     36      service"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words_df['Word'] = top_words_df['pos'].apply(lambda x: x[0]) # split the tuple of POS\n",
    "top_words_df = top_words_df.drop('pos', 1) # drop the previous column\n",
    "top_words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('access', 80), ('system', 79), ('application', 46), ('support', 38), ('service', 36), ('environment', 34), ('technology', 32), ('oracle', 32), ('year', 29), ('solution', 28), ('knowledge', 28), ('data', 27), ('database', 26), ('computer', 25), ('directory', 23), ('position', 22), ('issue', 21), ('development', 21), ('administration', 20), ('design', 19), ('role', 18), ('process', 18), ('organization', 18), ('performance', 18), ('office', 17), ('documentation', 17), ('staff', 17), ('skill', 17), ('customer', 16), ('benefit', 15), ('problem', 15), ('account', 15), ('platform', 14), ('value', 14), ('policy', 14), ('implementation', 13), ('request', 13), ('program', 13), ('community', 13), ('server', 13), ('university', 12), ('azure', 12), ('product', 11), ('task', 11), ('project', 11), ('culture', 11), ('berkeley', 11), ('practice', 11), ('area', 10), ('department', 10), ('integration', 10), ('procedure', 10), ('client', 10), ('people', 10), ('configuration', 10), ('integrity', 10), ('infrastructure', 10), ('life', 10), ('device', 10), ('enterprise', 10), ('standard', 9), ('member', 9), ('career', 9), ('requirement', 9), ('perform', 9), ('report', 9), ('audit', 9), ('level', 9), ('certification', 9), ('principle', 9), ('assist', 9), ('plan', 9), ('and/or', 8), ('use', 8), ('resource', 8), ('group', 8), ('activity', 8), ('resolution', 8), ('manage', 8), ('degree', 8), ('cloud', 8), ('analysis', 8), ('tool', 8), ('growth', 7), ('partner', 7), ('improvement', 7), ('network', 7), ('ha', 7), ('relationship', 7), ('–', 7), ('effort', 7), ('hire', 7), ('vendor', 7), ('order', 7), ('backup', 7), ('contract', 7), ('siteminder', 7), ('part', 6), ('compliance', 6), ('condition', 6)]\n"
     ]
    }
   ],
   "source": [
    "subset_pos = top_words_df[['Word', 'count']]\n",
    "tuples_pos = [tuple(x) for x in subset_pos.values]\n",
    "\n",
    "print(tuples_pos)\n",
    "\n",
    "wordcloud = WordCloud()\n",
    "#wordcloud.generate_from_frequencies(tuples_pos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 2000x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "#plt.imshow(wordcloud, interpolation=\"bilinear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. BiGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(active, directory)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, year)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(computer, system)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(oracle, sso)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(bachelor, degree)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(sql, server)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(account, access)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bigram  count\n",
       "0  (active, directory)     14\n",
       "1            (2, year)     11\n",
       "2   (computer, system)     10\n",
       "3        (oracle, sso)     10\n",
       "4   (bachelor, degree)      9\n",
       "5        (sql, server)      8\n",
       "6    (account, access)      6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgs = nltk.bigrams(token_list2)\n",
    "fdist2 = nltk.FreqDist(bgs) # selecting bigrams from tokens\n",
    "bgs_100 = fdist2.most_common(100) # top-100 bigrams\n",
    "bgs_df = pd.DataFrame(bgs_100, columns = ('bigram','count'))\n",
    "bgs_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(least, 2, year)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(written, interpersonal, skill)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(version, 11g, 1112x)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(11g, 1112x, 12c)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1112x, 12c, 1221x)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(demonstrate, potential, perform)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(potential, perform, function)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             trigram  count\n",
       "0                   (least, 2, year)      3\n",
       "1    (written, interpersonal, skill)      3\n",
       "2              (version, 11g, 1112x)      3\n",
       "3                  (11g, 1112x, 12c)      3\n",
       "4                (1112x, 12c, 1221x)      3\n",
       "5  (demonstrate, potential, perform)      2\n",
       "6     (potential, perform, function)      2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs = nltk.trigrams(token_list2) \n",
    "fdist3 = nltk.FreqDist(tgs) # selecting trigrams from tokens\n",
    "tgs_100 = fdist3.most_common(100) # top-100 trigrams\n",
    "tgs_df = pd.DataFrame(tgs_100, columns = ('trigram','count'))\n",
    "tgs_df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>count</th>\n",
       "      <th>phrase</th>\n",
       "      <th>filter_tgs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(least, 2, year)</td>\n",
       "      <td>3</td>\n",
       "      <td>least 2 year</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(written, interpersonal, skill)</td>\n",
       "      <td>3</td>\n",
       "      <td>written interpersonal skill</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(version, 11g, 1112x)</td>\n",
       "      <td>3</td>\n",
       "      <td>version 11g 1112x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(11g, 1112x, 12c)</td>\n",
       "      <td>3</td>\n",
       "      <td>11g 1112x 12c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1112x, 12c, 1221x)</td>\n",
       "      <td>3</td>\n",
       "      <td>1112x 12c 1221x</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           trigram  count                       phrase  \\\n",
       "0                 (least, 2, year)      3                 least 2 year   \n",
       "1  (written, interpersonal, skill)      3  written interpersonal skill   \n",
       "2            (version, 11g, 1112x)      3            version 11g 1112x   \n",
       "3                (11g, 1112x, 12c)      3                11g 1112x 12c   \n",
       "4              (1112x, 12c, 1221x)      3              1112x 12c 1221x   \n",
       "\n",
       "   filter_tgs  \n",
       "0       False  \n",
       "1       False  \n",
       "2       False  \n",
       "3       False  \n",
       "4       False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_df['phrase'] = tgs_df['trigram'].apply(lambda x: x[0]+\" \"+x[1]+\" \"+x[2]) # merging the tuple into a string\n",
    "tgs_df['filter_tgs'] = tgs_df['phrase'].str.contains(punctuation) # finding strings with numbers and punctuation\n",
    "tgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_57644/1650553726.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tgs_df = tgs_df.drop('trigram', 1)\n",
      "/var/folders/1q/13518n1s1n75fzdx64wlyz5w0000gn/T/ipykernel_57644/1650553726.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  tgs_df = tgs_df.drop('filter_tgs', 1) # removing the excess columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>least 2 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>written interpersonal skill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>version 11g 1112x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11g 1112x 12c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1112x 12c 1221x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>demonstrate potential perform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>potential perform function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>perform function outlined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>function outlined position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>operating system application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                         phrase\n",
       "0      3                   least 2 year\n",
       "1      3    written interpersonal skill\n",
       "2      3              version 11g 1112x\n",
       "3      3                  11g 1112x 12c\n",
       "4      3                1112x 12c 1221x\n",
       "5      2  demonstrate potential perform\n",
       "6      2     potential perform function\n",
       "7      2      perform function outlined\n",
       "8      2     function outlined position\n",
       "9      2   operating system application"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgs_df = tgs_df[tgs_df.filter_tgs == False] # removing strings with numbers and punctuation\n",
    "tgs_df = tgs_df.drop('trigram', 1)\n",
    "tgs_df = tgs_df.drop('filter_tgs', 1) # removing the excess columns\n",
    "tgs_df.reset_index()\n",
    "tgs_df.head(10) #Final trigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (default, Aug 25 2020, 09:23:57) \n[Clang 12.0.0 (clang-1200.0.32.2)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
